<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Machine Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Machine Learning</h1>
									</header>

									<span class="image main"><img src="images/ML header.jpg" alt="" /></span>

									<p></p>
									
									<hr class="major" />

									<h2>In this module, I shall...</h2>
									<blockquote>
										<ul>
											<li>Learn about the key paradigms and algorithms in machine learning.</li>
											<li>Get an understanding of data analytics based on machine learning and using modern programming tools, such as Python or R.</li>
											<li>Experience how machine learning and data analytics can be used in real-world applications</li>
											<li>Acquire the ability to gather and synthesise information from multiple sources to aid in the systematic analysis of complex problems using machine learning tools and algorithms.</li>
										</ul>
									</blockquote>
									<h2>On completion of this module, I will be able to...</h2>
									<blockquote>
										<ul>
											<li>Articulate the legal, social, ethical, and professional issues faced by machine learning professionals.</li>
											<li>Understand the applicability and challenges associated with different datasets for the use of machine learning algorithms.</li>
											<li>Apply and critically appraise machine learning techniques to real-world problems, particularly where technical risk and uncertainty is involved. </li>
											<li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real-life perspectives on team roles and organisation.</li>
										</ul>
									</blockquote>

									<hr class="major" />

									<h2>Artefacts Created During Module</h2>
									<p></p>
										<h3>Development Team Project: Project Report</h3>
											<h4><i>Objective: Posing as a team of Data Scientists, answer a business question formulated using
												<a href="https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data" target="_blank"> this AirBNB dataset </a>
												that can be solved with data analytics. Create a report which can easily be interpreted by the executive board members of the Airbnb</i></h4>
											<blockquote>
												<p>Learning Outcomes</p>
												<ul>
													<li>Understand the applicability and challenges associated with different datasets for the use of machine learning algorithms.</li>
													<li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real-life perspectives on team roles and organisation.</li>
												</ul>
											</blockquote>
											<p>
												
												
												This assignment involved several phases of collaboration. After some brainstorming and discussion about our individual strengths, the team decided that creating a nal nal database for an organization that needed their HR hiring process optimized would be best.
												When considering the design, first we visualized the <i>flow of the data</i>. 
												<span class="image fit"><img src="images/DBD Project Report Visual Flow.png" alt="" /></span>
												This involved considering what data the organization might want in their new HR database, what categories the data would need to be divided into, and how the data would be input into and move around within the database.
												After a couple more rough drafts, we landed on what seemed to be a <i>concrete database design</i>. 
												<span class="image fit"><img src="images/DBD Project Report database design.png" alt="" /></span>
												After that, we collectively wrote the finalized 
												<a href="Assignments/DBD Project Report.pdf" target="_blank"> "project report"</a> that communicated our design and build to the hypothetical organization. 
											</p>
											
										<hr class="major" />

										<h3>Development Individual Project: Executive Summary</h3>
											<h4><i>Objective: Create an executive summary of the completed design and build of the logical database based on the project report sumbitted by your team.</i></h4>
											<blockquote>
												<p>Learning Outcomes</p>
												<ul>
													<li>Design, develop and evaluate solutions for processing datasets and solving complex problems in various environments using relevant programming paradigms.</li>
													<li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>
												</ul>
											</blockquote>
											<p>This assignment involved building off of the previous project report and finalizing the database design and build. This assignment also called for a more critical analysis of the database, with reference to the literature 
												on the pros and cons of our database design and build. In the project report assignment, the team had originally decided to create a relational database, as this is one of the most commonly used databases within HR (Moura, 2021). 
												However, when I did further research I discovered that while relational databases are used, they might not be the best option in the future. I go more in depth on this in section 4.2 of the 
												<a href="Assignments/Executive Summary.pdf" target="_blank"> "executive summary"</a>, and I personally think it was the most fun and interesting part of the report to write. Perhaps relational databases are 
												a thing of the past, and we will all move towards NoSQL or graph databases in order to manage the large amount of data transactions that occur in the current "Big Data Era" (Bara et al., 2015). 
											</p>

										<hr class="major" />
										<h3>Normalization Task</h3>
											<h4><i>Objective: Normalize a table of data to the 3rd Normal Form (3NF), showing each step of the process.</i></h4>
											<blockquote>
												<p>Learning Outcomes</p>
												<ul>
													<li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
													<li>Design, develop and evaluate solutions for processing datasets and solving complex problems in various environments using relevant programming paradigms.</li>
													<li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>
												</ul>
											</blockquote>
											<p>The data to be normalized was first given as such:
												<span class="image fit"><img src="images/DBD Non Normalized Table.png" alt="" /></span>
												This data does not conform to the 1st Normal Form (1NF). To be in 1NF, the relation must be contain an atomic value. In other words, there can be no repeating groups. 
												The following image shows how the data looks after normalizing it to the 1st Normal Form.
												<span class="image fit"><img src="images/DBD 1NF Table.png" alt="" /></span>
												To further normalize the table, partial dependencies must be removed. This transition to the 2nd Normal Form (2NF)results in several different tables. 
												<span class="image fit"><img src="images/DBD 2NF Table.jpg" alt="" /></span>
												After this, the final step to normalizing the table of data to the 3rd Normal Form is to ensure that no transitive dependencies exist. This results in the final following schema:
												<span class="image fit"><img src="images/DBD 3NF Table.jpg" alt="" /></span>
												Five tables were made in total, a Student table, a Course table, an Enrollment table, a Teacher table, and an Exam board table. 
											</p>
										
										<hr class="major" />

										<h3>Data Build</h3>
											<h4><i>Objective: Build a relational database system with linked tables based  off of the Normalization Task data.</i></h4>
											<blockquote>
												<p>Learning Outcomes</p>
												<ul>
													<li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
													<li>Design, develop and evaluate solutions for processing datasets and solving complex problems in various environments using relevant programming paradigms.</li>
													<li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>
												</ul>
											</blockquote>
											<p>This assignment builds off of the Normalization Task, which had us normalize a given table to the 3rd Normal Form. In this assignment, we build a relational database system, with linked tables, to demonstrate our knowledge of primary and secondary keys. 
												Here is the following SQL code used to create the relational database system:
													<pre><code>
-- Create Student Table
CREATE TABLE Student (
    StudentNumber INT PRIMARY KEY,
    StudentName VARCHAR(100),
    ExamScore INT,
    Support BOOLEAN,
    DateOfBirth DATE
);

-- Create Course Table
CREATE TABLE Course (
    CourseID INT PRIMARY KEY,
    CourseName VARCHAR(100)
);

-- Create Enrollment Table
CREATE TABLE Enrollment (
    StudentNumber INT,
    CourseID INT,
    PRIMARY KEY (StudentNumber, CourseID),
    FOREIGN KEY (StudentNumber) REFERENCES Student(StudentNumber),
    FOREIGN KEY (CourseID) REFERENCES Course(CourseID)
);

-- Create Teacher Table
CREATE TABLE Teacher (
    TeacherName VARCHAR(100),
    CourseID INT,
    PRIMARY KEY (TeacherName, CourseID),
    FOREIGN KEY (CourseID) REFERENCES Course(CourseID)
);

-- Create ExamBoard Table
CREATE TABLE ExamBoard (
    ExamBoard VARCHAR(100),
    CourseID INT,
    PRIMARY KEY (ExamBoard, CourseID),
    FOREIGN KEY (CourseID) REFERENCES Course(CourseID)
);

-- Insert data into Student Table
INSERT INTO Student (StudentNumber, StudentName, ExamScore, Support, DateOfBirth) VALUES
(1001, 'Bob Baker', 78, FALSE, '2001-08-25'),
(1002, 'Sally Davies', 55, TRUE, '1999-10-02'),
(1003, 'Mark Hammill', 90, FALSE, '1995-06-05'),
(1004, 'Anas Ali', 70, FALSE, '1980-08-03'),
(1005, 'Cheuk Yin', 45, TRUE, '2002-05-01');

-- Insert data into Course Table
INSERT INTO Course (CourseID, CourseName) VALUES
(1, 'Computer Science'),
(2, 'Maths'),
(3, 'Physics'),
(4, 'Biology'),
(5, 'Music');

-- Insert data into Enrollment Table
INSERT INTO Enrollment (StudentNumber, CourseID) VALUES
(1001, 1),
(1001, 2),
(1002, 3),
(1002, 2),
(1002, 4),
(1002, 5),
(1003, 1),
(1003, 2),
(1003, 3),
(1004, 2),
(1004, 3),
(1004, 4),
(1005, 1),
(1005, 2),
(1005, 5);

-- Insert data into Teacher Table
INSERT INTO Teacher (TeacherName, CourseID) VALUES
('Mr Jones', 1),
('Ms Parker', 2),
('Mr Peters', 3),
('Mrs Patel', 4),
('Ms Daniels', 5);

-- Insert data into ExamBoard Table
INSERT INTO ExamBoard (ExamBoard, CourseID) VALUES
('BCS', 1),
('EdExcel', 2),
('OCR', 3),
('WJEC', 4),
('AQA', 2),
('AQA', 5);
													</code></pre>
													Then we tested referential integrity. 
													<pre><code>
-- This should fail because there is no StudentNumber 9999
INSERT INTO Enrollment (StudentNumber, CourseID) VALUES (9999, 1);

-- This should fail because there is no CourseID 999
INSERT INTO Enrollment (StudentNumber, CourseID) VALUES (1001, 999);

-- This should fail because there is no CourseID 999
INSERT INTO Teacher (TeacherName, CourseID) VALUES ('Mr Unknown', 999);

-- This should fail because there is no CourseID 999
INSERT INTO ExamBoard (ExamBoard, CourseID) VALUES ('Unknown Board', 999);
													</code></pre>
												As all the tests failed, the database should be in 3NF and maintain referential integrity. 										
											</p>
										<hr class="major" />
										<h3>Data Cleaning</h3>
											<h4><i>Objective: Follow textbook instructions to clean data</i></h4>
											<blockquote>
												<p>Learning Outcomes</p>
												<ul>
													<li>Clean and transform data using the data pipeline as a guide.</li>
													<li>Examine and understand factors that affect data cleaning.</li>
													<li>Understand requirements for design automation.</li>
												</ul>
											</blockquote>
											<p>For this assignment, the textbook: "Data Wrangling with Python" was referred to. I used the textbook's repository to access two .csv files that required cleaning. These files were MICS surveys from UNICEF. After downloading the files, I then followed the instructions within the textbook to properly clean the datasets using Python. 
												The first step was to replace the headers by using header subsitution in Python. The below are examples of how I achieved that by following the Python code examples in the textbook, with some of the code being modified to work with Python 3. 
												<span class="image fit"><img src="images/DBD Header cleaning.png" alt="" /></span>
												<span class="image fit"><img src="images/DBD Header cleaning 2.png" alt="" /></span>
												After running the above code, there were so many matches that my jupyter notebook crashed! 
												<span class="image fit"><img src="images/DBD Header cleaning 3.png" alt="" /></span>
												The textbook and lecturecast also displayed how to do the same task using a zip method in Python. Using the zip method it was discovered that the lengths of the data and header rows are not the same, indicating that the MICS surveys may have a different number of questions for different countries. 
												Next, the textbook details a script that zips the header and data together. Unfortunately, my computer disagreed with such a large script. However, reading the textbook allowed me to understand the necessity of cleaning data 
												and ensuring that headers match, that dupes need to be identified and corrected, missing data needs to be dealt with, and data might even need to be merged or manipulated in order to be used to its utmost potential. 
											</p>
										
										<hr class="major" />

										<h3>API Security Requirements</h3>
											<h4><i>Objective: Evaluate the security requirements of an API of your choice and write a brief security requirements specification which mitigate against any risks associated with the API.</i></h4>
											<blockquote>
												<p>Learning Outcomes</p>
												<ul>
													<li>Identify and manage challenges, security issues and risks, limitations, and opportunities in data wrangling.</li>
													<li>Critically analyse data wrangling problems and determine appropriate methodologies, tools, and techniques (involving preparing, cleaning, exploring, creating, optimising and evaluating big data) to solve them.</li>
													<li>Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real life perspectives on team roles and organisation.</li>
												</ul>
											</blockquote>
											<p> 
											This assignment is very straightforward. One of the readings for this part of the module was the article “What is an API and Why Ecommerce Sites Use Them” (Big Commerce, n.d.). 
											The article first defines what an API is: “…an acronym for application programming interface…a set of protocols for building application software.”.  After understanding what an API is, 
											now we must identify one so we can evaluate their safety requirements. 
											<br>
											<br>
												The API that I chose was the Google Maps API. This API allows developers to integrate Google Maps into their own applications. Google Maps also has their own security guidance page that details the 
											recommended best practices to follow for increased security, which may be helpful to those who wish to use the API (Google Developers, n.d.). The main way Google Maps ensures applications that use 
											their API are secure is to enforce the usage of API keys or Oauth. The major security concern appears to be unauthorized access to the API keys. Google recommends restricting the keys and deleting 
											any unused ones, as well as regularly checking key and API usage for unusual activity patterns to identify potential vulnerabilities. As this was originally meant to be a team activity, I took the 
											opportunity to discuss and evaluate the security requirements of my chosen API with my father, who was a computer engineer before he retired. He brought up the fact that the data would also have to be 
											encrypted to ensure the data is stored safely and if there is a data breach, the users are protected. Discussing information with others is a great way to further your understanding of a topic. 
											
											</p>
									
									<hr class="major" />

									<h2>Reflections</h2>
										<h3>Reflect on your knowledge gained in this module</h3>
											<p>
												As I have finished this module, I feel I have gained a sufficient understanding of the different data extraction, exploration, cleaning, and modelling techniques covered. However, I do believe that 
												I also must build on these skills further, as I feel as if I created a foundation of understanding, but I will struggle to fully implement all the skills I gained when applying them to real life situations. 
												In particular, I struggle with data cleaning. I think proper data cleaning is quite difficult. Data cleaning is the foundation of manipulating data, and there is much more to it than I originally thought. 
												As K.A. (2019) says, “Data cleaning seems to be a one-off process, but nothing could be further from the truth…The idea is we try to end up having the smallest meaningful dataset for our model. 
												I pity the fool who undertakes it.”. Ensuring that you are following a data cleaning pipeline helps, but there are still so many different steps that you could include, or exclude, depending on your specific dataset. 
												<br>
												<br>
												I currently lack the knowledge (or at the very least the confidence) to make the decisions on what steps to include in my data cleaning pipeline by myself, and I very much rely on the textbooks or 
												google to direct me. To rectify this, I am unsure of what to do other than just continue applying the skills I have learned. Perhaps this is one of those skills where you must continuously use it in 
												order to understand how to use it. If you stop speaking a language, you eventually lose some of your ability to speak it, but if you keep speaking, you will only get more and more fluent. 
												This is the approach I am going to take with the knowledge and skills I have gained in this module.

											</p>
										<h3>Reflect on your individual contributions to team activities and your experience as a member of a development team</h3>
											<p>
												I believe that I contributed to the team activities to the best of my abilities. While I may not have written in the collaborative discussions, or been able to attend any of the seminars, 
												I did my best to ensure that my team members had a reliable and engaged participant that they could count on. From creating the first draft, to working on multiple new drafts with input from others, 
												to editing the final draft to ensure proper grammar as well as stay within the word count, I believe that there is plenty of proof that I contributed more than enough as a member of the development team. 
												<br>
												<br>
												Figure 1. Creating the first draft.
												<span class="image fit"><img src="images/DBD collaboration.png" alt="" /></span>
												Figure 2. Working on other drafts with the help of a team member.
												<span class="image fit"><img src="images/DBD collaboration 2.png" alt="" /></span>
												Figure 3. Working on editing the final draft to stay within the word count.
												<span class="image fit"><img src="images/DBD collaboration 3.png" alt="" /></span>
												However, I do realize that I am lacking when it comes to participating in optional team activities. I would truly appreciate a larger amount of team projects, as I loved working 
												with others in an environment where everyone was pushed to do their best, as most people wanted to get the best grade possible. 
												When I am not pushed to work with others, I find myself reluctant to step out of my comfort zone and contribute. Not only is this not a good mentality to have in an industry where you constantly 
												must learn and grow, but it actively stifles my current learning and prevents me from getting along with my peers and collaborating effectively. I recently joined a WhatsApp group with 
												other members that are also working on their master’s in data science and have contributed to the conversation there as a way 
												to open up a bit and work on expanding my comfort zone to include these kinds of conversations. 
 

											</p>
										<h3>Reflect on the impact this module has had on your professional/personal development</h3>
											<p>
												This area is where I felt quite a bit of impact, as this module gave me a lot more confidence when it came to working with data as a part of a team. As an individual with a background in psychology, 
												I have no formal education in computer science apart from this degree. Before this degree, the main way I studied data science was through courses I took on my own and other forms of self-study. 
												I do struggle with a sense of impostor syndrome even when I work on solo assignments, so when I first started working on the team project with people who are currently working jobs within the data and 
												technology sector, I was very worried about my ability to keep up. I realized early on that I had nothing to worry about. The modules that I have taken so far have prepared me well, and after working on 
												Units 1-6 in this module I was more than capable of collaborating with my peers and creating a report with my team that I could be proud of. 
												<br>
												<br>	
												This module helped me realize that I have come much farther than I thought, and that I do have a place in data science regardless of my background. My background may actually benefit me in certain ways, as 
												I have a solid understanding of research methods, statistics, and soft skills such as collaboration, communication, and empathy that others may not have developed as much. This confidence has also given me 
												a professional opportunity, as I have been invited to more interviews for data related internships in the past few weeks than ever before, despite the fact that I have been applying to them for a few months. 
												While I may have started the race to data science literacy several hundred meters behind everyone else, I’ve worked hard to catch up and run alongside everyone else. 

											</p>

									<h2>References</h2>
										<ul>
											<li>Bara, A., Botha, J., Belciu, A. &Nedelcu, B. (2015) Exploring Data in Human Resources 
													Big Data. Database Systems Journal VI(3/2015): 3-10. Available from: 
													https://www.dbjournal.ro/archive/21/21_1.pdf [Accessed 20 May 2024]</li>
											<li>BigCommerce. (n.d.). What is an API? Available at: https://www.bigcommerce.com/articles/ecommerce-website-development/what-is-an-api/ [Accessed 30 May 2024].</li>
											<li>Google Developers. (n.d.). API security best practices. Available at: https://developers.google.com/maps/api-security-best-practices [Accessed 30 May 2024].</li>
											<li>K.A. (2019) Why Data Cleaning is the Hardest Part of a Data Scientist’s Job? Available at: https://medium.com/@karwan_j/why-data-wrangling-is-the-hardest-part-of-a-data-scientists-job-16b186bb94fc [Accessed 1 June 2024]</li>
											<li>Moura, R. (2021) Graph Databases for HR Relationships. Available from:
													https://repositorio-aberto.up.pt/handle/10216/137426 [Accessed 24 May 2024]</li>
										</ul>
									
								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Home</a></li>
										<li><a href="About.html">About</a></li>
										<li><a href="Resume.html">Resume</a></li>
										<li>
											<span class="opener">University Modules</span>
											<ul>
												<li><a href="TDP.html">The Data Professional</a></li>
												<li><a href="VD.html">Visualizing Data</a></li>
												<li><a href="NA.html">Numerical Analysis</a></li>
												<li><a href="DBD.html">Deciphering Big Data</a></li>
												<li><a href="ML.html">Machine Learning</a></li>
											</ul>
										</li>
										<li><a href="Project.html">MSc Computing Project</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Feel free to contact me for any questions you might have.</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href=mailto:"dahall423@mgmail.com">dahall423@gmail.com</a></li>
										<li class="icon solid fa-phone">(+47) 405-20-636</li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; License: Creative Commons. All rights reserved. Images: <a href="https://unsplash.com">Unsplash</a>. Original Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
